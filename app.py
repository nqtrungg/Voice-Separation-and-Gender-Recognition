import streamlit as st
import numpy as np
import librosa
import soundfile as sf
from io import BytesIO
from Utils import create_model
from sound_sep import SoundSeparation
import tempfile
import pyaudio
import wave

# Cáº¥u hÃ¬nh Streamlit
st.set_page_config(page_title="Voice Separation & Gender", page_icon="ðŸŽ™ï¸", layout="centered")
st.title("ðŸŽ™ï¸ Voice Separation & Gender")
st.write("Ghi Ã¢m trá»±c tiáº¿p hoáº·c táº£i lÃªn má»™t file Ã¢m thanh (.wav) Ä‘á»ƒ tÃ¡ch giá»ng vÃ  nháº­n diá»‡n giá»›i tÃ­nh.")

# Khá»Ÿi táº¡o mÃ´ hÃ¬nh
@st.cache_resource
def load_model():
    model = create_model()
    model.load_weights("results/model.h5")
    return model

if "sound_sep" not in st.session_state:
    st.session_state.sound_sep = SoundSeparation(config_path="config.yaml")
if "gender_model" not in st.session_state:
    st.session_state.gender_model = load_model()

# HÃ m ghi Ã¢m
def record_audio(duration=10):
    """Ghi Ã¢m trá»±c tiáº¿p tá»« micro vÃ  tráº£ vá» dá»¯ liá»‡u Ã¢m thanh."""
    CHUNK, FORMAT, CHANNELS, RATE = 1024, pyaudio.paInt16, 1, 16000
    p = pyaudio.PyAudio()
    stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)
    
    frames = [stream.read(CHUNK) for _ in range(0, int(RATE / CHUNK * duration))]
    stream.stop_stream()
    stream.close()
    p.terminate()
    
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_wav:
        wf = wave.open(temp_wav, "wb")
        wf.setnchannels(CHANNELS)
        wf.setsampwidth(p.get_sample_size(FORMAT))
        wf.setframerate(RATE)
        wf.writeframes(b"".join(frames))
        return temp_wav.name

# HÃ m trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng
def extract_feature(file_name, **kwargs):
    """
    TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« file Ã¢m thanh `file_name`.
    
    CÃ¡c Ä‘áº·c trÆ°ng há»— trá»£:
        - MFCC (mfcc)
        - Chroma (chroma)
        - MEL Spectrogram (mel)
        - Contrast (contrast)
        - Tonnetz (tonnetz)
    
    VÃ­ dá»¥:
    `features = extract_feature(path, mel=True, mfcc=True)`
    """
    try:
        mfcc = kwargs.get("mfcc")
        chroma = kwargs.get("chroma")
        mel = kwargs.get("mel")
        contrast = kwargs.get("contrast")
        tonnetz = kwargs.get("tonnetz")

        # Äá»c file Ã¢m thanh
        X, sample_rate = librosa.load(file_name, sr=None)
        result = np.array([])

        # TÃ­nh toÃ¡n STFT náº¿u cáº§n cho chroma hoáº·c contrast
        stft = np.abs(librosa.stft(X)) if chroma or contrast else None

        # TrÃ­ch xuáº¥t MFCC (n_mfcc=13 Ä‘á»ƒ phÃ¹ há»£p vá»›i model)
        if mfcc:
            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)
            result = np.hstack((result, mfccs))

        # TrÃ­ch xuáº¥t Chroma
        if chroma:
            chroma_feature = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)
            result = np.hstack((result, chroma_feature))

        # TrÃ­ch xuáº¥t Mel Spectrogram
        if mel:
            mel_feature = np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T, axis=0)
            result = np.hstack((result, mel_feature))

        # TrÃ­ch xuáº¥t Spectral Contrast
        if contrast:
            contrast_feature = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T, axis=0)
            result = np.hstack((result, contrast_feature))

        # TrÃ­ch xuáº¥t Tonnetz
        if tonnetz:
            tonnetz_feature = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T, axis=0)
            result = np.hstack((result, tonnetz_feature))

        return result

    except Exception as e:
        st.error(f"âŒ Lá»—i khi trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng: {str(e)}")
        return None

# Chá»n nguá»“n Ã¢m thanh
option = st.radio("ðŸ“Œ Chá»n nguá»“n Ã¢m thanh:", ["ðŸŽ¤ Ghi Ã¢m trá»±c tiáº¿p", "ðŸ“‚ Táº£i file WAV"])

uploaded_file = None
if option == "ðŸŽ¤ Ghi Ã¢m trá»±c tiáº¿p" and st.button("ðŸŽ™ï¸ Báº¯t Ä‘áº§u ghi Ã¢m"):
    uploaded_file = record_audio()
    st.success(f"âœ… ÄÃ£ ghi Ã¢m xong!")
elif option == "ðŸ“‚ Táº£i file WAV":
    uploaded_file = st.file_uploader("ðŸ“¤ Chá»n file WAV", type=["wav"])

# Xá»­ lÃ½ file Ã¢m thanh
if uploaded_file:
    st.subheader("ðŸ”Š Audio Gá»‘c")
    st.audio(uploaded_file, format="audio/wav")
    
    mixture, original_sample_rate = st.session_state.sound_sep.read_audio_file(uploaded_file)
    diarization, sources_hat = st.session_state.sound_sep.separate_sound(mixture, original_sample_rate)
    
    if sources_hat is None:
        st.error("âš ï¸ KhÃ´ng thá»ƒ tÃ¡ch giá»ng. Thá»­ láº¡i vá»›i file khÃ¡c.")
    else:
        st.subheader("ðŸ“Š Káº¿t quáº£")
        num_sources = sources_hat.data.shape[1]
        st.write(f"ðŸ”Š **Sá»‘ giá»ng nÃ³i tÃ¡ch Ä‘Æ°á»£c:** {num_sources}")
        
        for i in range(num_sources):
            source = sources_hat[:, i]
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_wav:
                sf.write(temp_wav.name, source, original_sample_rate, format='wav')
                temp_path = temp_wav.name
            
            st.subheader(f"ðŸ—£ï¸ Giá»ng {i+1}")
            st.audio(temp_path, format="audio/wav")
            
            features = extract_feature(temp_path, mel=True)
            
            if features is not None:
                features = features.reshape(1, -1)  # Äá»‹nh dáº¡ng Ä‘áº§u vÃ o cho mÃ´ hÃ¬nh

                # Kiá»ƒm tra sá»‘ lÆ°á»£ng Ä‘áº·c trÆ°ng cÃ³ khá»›p vá»›i model khÃ´ng
                expected_features = 128  # Model yÃªu cáº§u 128 Ä‘áº·c trÆ°ng
                if features.shape[1] != expected_features:
                    st.error(f"âš ï¸ Lá»—i: Model yÃªu cáº§u {expected_features} Ä‘áº·c trÆ°ng, nhÆ°ng nháº­n Ä‘Æ°á»£c {features.shape[1]}.")
                else:
                    # Dá»± Ä‘oÃ¡n giá»›i tÃ­nh
                    model = st.session_state.gender_model
                    male_prob = model.predict(features)[0][0]
                    female_prob = 1 - male_prob
                    gender = "ðŸ§‘ Male" if male_prob > female_prob else "ðŸ‘© Female"

                    # Hiá»ƒn thá»‹ káº¿t quáº£
                    st.write(f"**Giá»›i tÃ­nh dá»± Ä‘oÃ¡n:** {gender}")
                    st.write(f"ðŸ”µ **Nam:** {male_prob * 100:.2f}%  |  ðŸ”´ **Ná»¯:** {female_prob * 100:.2f}%")
                
# streamlit run app.py